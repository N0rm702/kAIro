# -*- coding: utf-8 -*-
"""main.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1DB5yyXXWBmkn182fk7f-52oLhpdGo4Ns
"""

from getpass import getpass
import time
import os #------ Thougth of adding a wait animation while the bot fetched responses .
import sys#------/////
#os.environ["OPENAI_API_KEY"] = getpass("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 ")
from langchain_core.messages import HumanMessage
#from langchain_openai import ChatOpenAI
from langchain.tools import tool
#from langgraph.prebuilt import create_react_agent
from dotenv import load_dotenv
from bytez import Bytez
sdk = Bytez("dfad040484cf3d11793bbb27fb210555")


load_dotenv()

def main():
   # model = ChatOpenAI(temperature=0)
    model = sdk.model("katanemo/Arch-Router-1.5B")

    #tools=[]
   # agent_executor = create_react_agent(model,tools)

    print("Welcome! I am Kairo.       Type'quit' to exit. ")
    print("How can I help you?")

    while True:
        user_input = input("\nYou : ").strip()
        if user_input.lower == 'quit':
            break


      #  print("\nkAIro: ",end = "")
       # for chunk in agent_executor.stream(
        #    {"message": [HumanMessage(content=user_input)]}
        #):
         #   if "agent" in chunk and "messages" in chunk["agent"]:
          #      for message in chunk ["agent"]["message"]:
           #             print(message.content,end="")

        #print()
        output, error = model.run([{"role": "user", "content": user_input}])
        if error:
          print(f"Error: {error}")
        elif output and "content" in output:
             print("kAIro : ",output["content"],end="")
        else:
          print("Sorry, Seems like there is a server issue ,Please try after some time. ")


if __name__ =="__main__":
      main()


try: # Done to check if the OpenAI library was working fine
    from langchain_openai import ChatOpenAI
    import langchain, openai
    print("langchain version:", langchain.__version__)
    print("langchain_openai import OK, openai version:", openai.__version__)
except Exception as e:
    print("Import error:", e)

# Unfortunately a free llm had to be imported so OpenAI was completely scrapped off.
#This was made in Google collab so it has commands to install dependencies/libraries.
